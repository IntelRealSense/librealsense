{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/IntelRealSense/librealsense/master/doc/img/realsense.png\" width=\"70%\" /><br><br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkVvgf-z4D1f"
   },
   "source": [
    "## Getting the Data\n",
    "This notebook showcases simple scene involving different materials - transparent aquarium walls and water. Depth from stereo as a technology is robuts to working underwater. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y2jplwqU4OHe",
    "outputId": "7a1685ad-c7ed-4fb9-9d76-eb728609f97f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://librealsense.intel.com/rs-tests/TestData/depth_under_water.bag\n",
    "print(\"Data is Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract and visualise the data we will need to import python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                        # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt           # 2D plotting library producing publication quality figures\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "print(\"Environment Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwiY9raM5nCH"
   },
   "source": [
    "## Capturing Frames\n",
    "Next, we will open depth and RGB streams from pre-recorded file and capture a set of frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cV1OkBYn55VH",
    "outputId": "0fbae060-91a8-4f2f-acf8-c20a0cf33dcd"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to resolve request. Request to enable_device_from_file(\"depth_under_water.bag\") was invalid, Reason: Failed to create ros reader: Error opening file: depth_under_water.bag",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e582678b4094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_device_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"depth_under_water.bag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Skip 5 first frames to give the Auto-Exposure time to adjust\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to resolve request. Request to enable_device_from_file(\"depth_under_water.bag\") was invalid, Reason: Failed to create ros reader: Error opening file: depth_under_water.bag"
     ]
    }
   ],
   "source": [
    "# Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_device_from_file(\"depth_under_water.bag\")\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "  pipe.wait_for_frames()\n",
    "  \n",
    "# Store next frameset for later processing:\n",
    "frameset = pipe.wait_for_frames()\n",
    "color_frame = frameset.get_color_frame()\n",
    "depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "pipe.stop()\n",
    "print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxlrWpLj6mkJ"
   },
   "source": [
    "## Visualising the Data\n",
    "The following code will align the two frames and visualise them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "5ajjn7Wq6nEg",
    "outputId": "737674f4-5314-470a-99c0-662f35444e02"
   },
   "outputs": [],
   "source": [
    "color = np.asanyarray(color_frame.get_data())\n",
    "colorizer = rs.colorizer()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "\n",
    "# Create alignment primitive with color as its target stream:\n",
    "align = rs.align(rs.stream.color)\n",
    "aligned_frameset = align.process(frameset)\n",
    "\n",
    "# Update color and depth frames:\n",
    "aligned_depth_frame = aligned_frameset.get_depth_frame()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())\n",
    "\n",
    "# Show the two frames together:\n",
    "images = np.hstack((color, colorized_depth))\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4TPljtWrUlw"
   },
   "source": [
    "> **Want to learn more?** Visit [realsense.intel.com](http://realsense.intel.com) and [github.com/IntelRealSense](http://www.github.com/IntelRealSense/librealsense)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Intel RealSense API",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
